{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5.1 Model Comparison Methods\n",
    "*How can we determine which model better fits our needs?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import scipy.stats as stats\n",
    "\n",
    "from utils import metropolis_hastings\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Path Constants\n",
    "if os.path.split(os.getcwd())[-1] != \"notebooks\":\n",
    "    os.chdir(os.path.join(\"..\"))\n",
    "    \n",
    "NETCDF_DIR = \"inference_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* Understanding of how to interpret WAIC, PSIS-LOO numerical metrics\n",
    "* Understanding of how to interpret plot_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infinite parameters and Infinite Models\n",
    "As Bayesian modelers not only do we have to handle infinite model parameters, we also have to handle infinite model defnitions.\n",
    "\n",
    "Take our water example from Section 1.3. \n",
    "$$\n",
    "\\theta = Uniform(0,1) \\\\\n",
    "p_{water} = Binom(\\theta)\n",
    "$$\n",
    "In this model we're evaulating not just one possible proportion of water on a planet, but an infinite amount of proportions from 0 to 1.\n",
    "\n",
    "But this begs the question why 0 to 1, or why even this model? This is also a valid model\n",
    "\n",
    "$$\n",
    "\\theta = Beta(1,5) \\\\\n",
    "p_{water} = Binom(\\theta)\n",
    "$$\n",
    "\n",
    "as is this model\n",
    "\n",
    "$$ \n",
    "\\theta = Uniform(0,1) \\\\\n",
    "\\sigma = Uniform(0,100) \\\\\n",
    "p_{water} = Norm(\\theta, \\sigma)\n",
    "$$\n",
    "\n",
    "### How do we pick?\n",
    "The flexibility to design whatever model you like is simultaneously the beauty and challenge of Bayesian modeling. While this philosophy is nice, for the practioner there still is the question of which model to choose. The reason this question is particularly challenging in Bayesian Statistics because we don't get just one prediction, we get an infinite amount of predictions in a distribution. However this does not mean that Bayesian analysis is not suspect to phenomena such as overfitting or excess complexity.\n",
    "\n",
    "Luckily there tools that help. In particular we'll cover *Widely Applicable Information Criteria* and how it's used in cojunction with `plot_compare`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A history of Information Theory\n",
    "When you hear Information Criterion you usually hear the words entropy, divergence, and deviance.  Let's briefly cover how these ideas build upon each other by walking through information theory.\n",
    "\n",
    "\n",
    "\\*Note:* This section heavily draws from Richard McElreath's examples. We'll be covering the material at a high level to get a full understanding we highly recommend his  [lectures](https://www.youtube.com/watch?v=gjrsYDJbRh0) and [books](https://www.amazon.com/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/1482253445/). \n",
    "\n",
    "\n",
    "To restate our prior question \"If have  3, or 5, or 10, estimates of the truth (also called models) which most usefully explains the truth, given the truth is also uncertain?\"\n",
    "\n",
    "Over the years a number of folks have contributed mathematical tools that help answer this question. In short the we go in this order\n",
    "\n",
    "1. How do we quantify uncertainty? (Information Entropy)\n",
    "2. How do we quantify the additional uncertainty added from an estimate when we know the truth? (KL Divergence)\n",
    "3. How do we estimate the additional uncertainty added from an estimate when we don't know the truth? (Deviance)\n",
    "4. How do we make sure we're ensure were underestimating uncertainty with complex models? (Information Criteria)\n",
    "\n",
    "This section is quite heavy of math. However it is not critical to understand the fine details, but more so the path of thinking.\n",
    "\n",
    "#### *Information Entropy*: Quantifying Uncertainty\n",
    "Weather is uncertain, and dice rolls are uncertain. But weather in certain areas is delightfully consistent, like my hometown of Orange County, and \"loaded\" are designed to be inconsistent.\n",
    "\n",
    "Information Entropy is a summarization of our uncertainty through the following formula  \n",
    "$$ H(p) = -\\sum_{n=1}^{N} p_{i}log(p_{i})$$\n",
    "\n",
    "#### *Divergence*: Quantifying additional uncertainty added from estimations of the truth\n",
    "Now that we can quantify the uncertainty in the distribution of reality, we can compare the uncertainty in the distribution our model to see how far off we are. The formula is as follows, where $p$ is the truth and $q$ is the estimate\n",
    "\n",
    "$$D_{kl} = -\\sum_{n=1}^{N} p_{i}(log(p_{i} - log(q_{i}))$$\n",
    "\n",
    "This is the idea of **divergence**, a measurement of the \"distance\" between two distributions. One important note this distance is not symmetric. For some quick intuition It was way more surprising for me to go from always sunny Los Angeles and experience snow in Wisconsin, than it is for a native Wisconsite to see sun in Los Angeles. People in Los Angeles only see sun, people in Wisconsin see sun and snow, therefore a Los Angeles is much farther removed from the reality of a mixed sunny/snowy climate, than a Wisconsinite is to an always sunny climate.\n",
    "\n",
    "#### *Deviance*: Estimating additional uncertainty because we don't know the truth using Deviance\n",
    "If we knew the truth then there wouldn't be a point to this tutorial, or the entire field of Statistics/Machine Learning. Since we don't know the truth this unfortunately means we can't use the formula above, but through some clever thinking it turns out you don't need to know the truth to compare two models, just how far off one model is relative from another. By using the truth data (The weather in the past), and a model estimates, its possible to calculate **Deviance** which is an estimate of the divergence\n",
    "\n",
    "#### *Information Criterion*: Making sure we're not overfitting to observed data using complex models\n",
    "Deviance uses data that has been observed to make an estimation. As it turns out it's impossible to use data you haven't seen because you haven't seen it. As it also turns out if you make models complex you can explain anything perfectly. *Information Criterion* uses both estimates of deviance and a penalizing for excess model complexity to \"score\" a model fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Criterion in detail\n",
    "Information Criterion calcuations are composed of two terms\n",
    "\n",
    "1. Estimate of a the deviance\n",
    "2. Number of parameters in the model\n",
    "\n",
    "Below is the summarized formula for Widely Applicable Information Criterion \n",
    "\n",
    "$$WAIC = -2 lppd + p_{WAIC}$$ \n",
    "\n",
    "*lppd* stands for log pointwise predictive density, and p_{WAIC} is an effective number of the parameters. Between the two we get an estimate of model \"accuracy\" balanced by it's model complexity\n",
    "\n",
    "### What about AIC, BIC, DIC?\n",
    "There are numerous variations of Information Criterion (IC) estimates. However due to assumptions in the calculations some of the IC's estimations are less general than others. As the name suggests Widely Applicable IC, is well, the most widely applicable. Richard McElreath goes through the full explanation in his book.\n",
    "\n",
    "## Enough with the math, what's the practical advice\n",
    "* Models with lower Information Criterion tend to be better\n",
    "* Lowest Information Criterion does not always mean the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Compare\n",
    "ArviZ provides plot compare as a way to summarize the results of WAIC, and in particular when comparing multiple models.\n",
    "\n",
    "**TODO** Add some example. Perhaps Richard McElreath's exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Methods Pareto Smoothed Importance Sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine example data to demonstrate these**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
